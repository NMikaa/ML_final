{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxbSd31EpWNI",
        "outputId": "45e89a63-c005-4bab-f899-95911e13ae50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PmS_9IPdpCnO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ML DATA/finalized_data.csv')"
      ],
      "metadata": {
        "id": "jxdwbbLSpXYU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TFIDFVectorizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = {}\n",
        "        self.idfs = {}\n",
        "\n",
        "    def _idf(self, corpus, unique_words):\n",
        "        idf_vals = {}\n",
        "        total_docs = len(corpus)\n",
        "        for word in tqdm(unique_words):\n",
        "            cnt = 0\n",
        "            for row in corpus:\n",
        "                if word in row.split(\" \"):\n",
        "                    cnt += 1\n",
        "            idf_vals[word] = 1 + math.log((1 + total_docs) / (1 + cnt))\n",
        "        return idf_vals\n",
        "\n",
        "    def fit(self, dataset):\n",
        "        if isinstance(dataset, (list,)):\n",
        "            unique_words = set()\n",
        "            for row in tqdm(dataset):\n",
        "                for word in row.split(\" \"):\n",
        "                    if len(word) < 2:\n",
        "                        continue\n",
        "                    unique_words.add(word)\n",
        "            unique_words = sorted(list(unique_words))\n",
        "            self.vocab = {j: i for i, j in enumerate(unique_words)}\n",
        "            self.idfs = self._idf(dataset, unique_words)\n",
        "        return self\n",
        "\n",
        "    def transform(self, dataset):\n",
        "        rows, cols, data = [], [], []\n",
        "        for idx, row in tqdm(enumerate(dataset), total = len(dataset)):\n",
        "            word_count = Counter(row.split(' '))\n",
        "            for word, count in word_count.items():\n",
        "                if word in self.vocab:\n",
        "                    tf = count / len(row.split(' '))\n",
        "                    tfidf = tf * self.idfs[word]\n",
        "                    rows.append(idx)\n",
        "                    cols.append(self.vocab[word])\n",
        "                    data.append(tfidf)\n",
        "        sparse_matrix = csr_matrix((data, (rows, cols)), shape=(len(dataset), len(self.vocab)))\n",
        "        return normalize(sparse_matrix, norm='l2', axis=1, copy=True)\n",
        "\n",
        "    def fit_transform(self, dataset):\n",
        "        self.fit(dataset)\n",
        "        return self.transform(dataset)"
      ],
      "metadata": {
        "id": "esR1P7GXJL2A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKOfcBlJp2We",
        "outputId": "6bf889e4-a8ad-4d76-e444-617eb5876704"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12251 entries, 0 to 12250\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   Unnamed: 0     12251 non-null  int64 \n",
            " 1   Category       12251 non-null  object\n",
            " 2   Category Area  12251 non-null  object\n",
            " 3   Text           12251 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 383.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# სამწუხაროდ ჩემი დაწერილი TF-IDF დიდ კორპუსზე ძალიან ნელა მუშაობს, ამიტომ მიწევს sklearn-ის გამოყენება :("
      ],
      "metadata": {
        "id": "7HpJVNa2JP6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer( norm=None)\n",
        "tfidf.fit(df[\"Text\"])\n",
        "weights = tfidf.transform(df[\"Text\"])\n"
      ],
      "metadata": {
        "id": "bqWveNv2qUfy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "le.fit(df[\"Category\"])\n",
        "\n",
        "df[\"Category\"] = le.transform(df[\"Category\"])"
      ],
      "metadata": {
        "id": "qMlV_m0gqjJh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(weights, df[\"Category\"], test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "m6AYCbDprQeb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Category\"].unique()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRzGoMv9sHEc",
        "outputId": "3db211cc-ad23-4de9-ced3-a2573000e949"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11,  9, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 21, 22, 24, 25, 23, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 45, 43, 44, 46, 47, 28, 31,  6, 20, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ახლა, ამ სეტაპით მინდა განვიხილო რამდენიმე მოდელი:\n",
        "\n",
        "1.   **KNN**\n",
        "\n",
        "2.   **logistic regression**\n",
        "\n",
        "3.   **SVM**\n",
        "\n",
        "4.   **Random Forest Regression**\n",
        "\n"
      ],
      "metadata": {
        "id": "Es26W_fbKoNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9qcGbH6dkLd",
        "outputId": "96942e9f-2866-4b03-8319-339bf2a8c334"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 118730)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "yTfuiMhssIhU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NqL3loJ3f3a",
        "outputId": "41313ef2-1068-46a4-9926-78069e3bc6eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36786296900489396"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ერთ-ერთი რამ, რაც უნდა გვექნა აქამდე და არ ვქენით, არის weight-ების dimension-ის ცვლილება. ერთ-ერთი ამის ვარიანტი არის SVD ფაქტორიზაცია."
      ],
      "metadata": {
        "id": "_cMlxJLVd7SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svd = TruncatedSVD(n_components=1200, random_state=42)\n",
        "reduced_weights = svd.fit_transform(weights)"
      ],
      "metadata": {
        "id": "f6C67pHvdUdH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(reduced_weights, df[\"Category\"], test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VuLb4tRPeQG7",
        "outputId": "29b73c99-ec67-467d-b0e7-88ebcff9e1f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6639477977161501"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=50),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'SVM': SVC()\n",
        "\n",
        "}\n",
        "accuracy_scores = {}\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores[model_name] = accuracy\n",
        "\n",
        "    # Print the accuracy\n",
        "    print(f'Accuracy of {model_name} on test set: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFlXyq2je3WH",
        "outputId": "2fffca65-ae7f-4747-9b2e-d031f44b031a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNN on test set: 0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of LogisticRegression on test set: 0.77\n",
            "Accuracy of RandomForest on test set: 0.72\n",
            "Accuracy of SVM on test set: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ეს სივი არის დაგენერირებული ჯიპიტის მიერ. არანაირი ინსტრუქცია, არანაირი დატის წმენდა არ ჩამიტარებია, არაფერი არ მითქვამს გარდა იმისა, რომ ფიტნეს ინსტრუქტორის სივი დაეგენერირებინა."
      ],
      "metadata": {
        "id": "62VojLKPoYKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text = \"\"\"John Doe\n",
        "123 Fitness Ave\n",
        "Gym City, GA 30303\n",
        "(555) 123-4567\n",
        "johndoe@example.com\n",
        "LinkedIn: linkedin.com/in/johndoe-fitness\n",
        "Objective\n",
        "Dynamic and certified Health and Fitness Instructor with over 5 years of experience specializing in creating personalized workout programs and conducting high-energy group fitness classes. Dedicated to helping clients achieve their health and fitness goals through tailored exercise routines and comprehensive nutritional guidance.\n",
        "Certifications\n",
        "Certified Personal Trainer, American Council on Exercise (ACE), 2018\n",
        "Group Fitness Instructor, National Academy of Sports Medicine (NASM), 2019\n",
        "CPR and First Aid, American Red Cross, 2020\n",
        "Yoga Instructor, 200-Hour RYT, Yoga Alliance, 2017\n",
        "Professional Experience\n",
        "Health and Fitness Instructor\n",
        "Gold's Gym, Atlanta, GA\n",
        "June 2020 – Present\n",
        "Design and implement customized fitness programs for over 100 regular clients, increasing their fitness performance by an average of 25%.\n",
        "Lead weekly group fitness classes, including Spin, HIIT, and Yoga, with an average attendance of 30 participants per class.\n",
        "Conduct bi-weekly workshops on nutrition and wellness that have improved client retention by 20%.\n",
        "Utilize motivational interviewing techniques to encourage client commitment and achieve a 95% success rate in client goal attainment.\n",
        "Fitness Coach\n",
        "Anytime Fitness, Atlanta, GA\n",
        "May 2015 – May 2020\n",
        "Spearheaded a successful bootcamp program that grew to include 50 regular participants.\n",
        "Collaborated with physical therapists to design rehabilitation exercises that safely engaged clients in physical activity post-injury.\n",
        "Increased gym membership by organizing monthly health and wellness fairs that attracted over 200 attendees.\n",
        "Education\n",
        "Bachelor of Science in Exercise Science\n",
        "Georgia State University, Atlanta, GA\n",
        "August 2011 – May 2015\n",
        "Skills\n",
        "Expert in creating tailored fitness programs.\n",
        "Proficient with digital fitness tracking systems like Fitbit and MyFitnessPal.\n",
        "Excellent communicator with effective client-facing skills.\n",
        "Knowledgeable in body mechanics and functional training.\n",
        "Fluent in Spanish.\n",
        "Professional Affiliations\n",
        "Member, National Strength and Conditioning Association (NSCA)\n",
        "Volunteer, Community Fitness Days, providing free fitness coaching to underprivileged communities\n",
        "References\n",
        "Available upon request.\"\"\"\n",
        "\n",
        "# Assuming 'vectorizer' is already fitted to a relevant corpus\n",
        "tfidf_weights = tfidf.transform([cv_text])\n",
        "reduced_weights = svd.transform(tfidf_weights)"
      ],
      "metadata": {
        "id": "m9khe3K0fbNG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DppCs6tlVEd",
        "outputId": "fd41daaa-3b8d-401a-8bc4-f12f49af6ed3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1200)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model in models.items():\n",
        "  label = model.predict(reduced_weights)\n",
        "\n",
        "  decoded_label = le.inverse_transform(label)\n",
        "  print(f\"Decoded label for {model_name}:\", decoded_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9hbEoynlLgW",
        "outputId": "aa889ad5-b34b-4b6b-8d0e-3ab930400400"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded label for KNN: ['Health and Fitness']\n",
            "Decoded label for LogisticRegression: ['Health and Fitness']\n",
            "Decoded label for RandomForest: ['Health and Fitness']\n",
            "Decoded label for SVM: ['Health and Fitness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "შემდეგ, გავტესტავ ჩემზე და ჩემი მეგობრების სივი-ებზე."
      ],
      "metadata": {
        "id": "XKEmJmmGopDu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7HelEPMlSha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}